{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example scraping notebook\n",
    "\n",
    "This notebook is a draft you can base your scraping project on. We scrape property listings in Iceland from mbl.is.\n",
    "\n",
    "We only scrape properties listed in the last 24 hours. In the first cell we use the requests library to submit the form data you can find [here](https://www.mbl.is/fasteignir/). We get back a response from the server with a URL we should redirect to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "payload={\"newtoday\":\"newtoday\"} # If you want to change the search criteria you should specify it here\n",
    "\n",
    "#session = requests.Session()\n",
    "r = requests.post('https://www.mbl.is/fasteignir/query/',data=payload)\n",
    "url = r.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the result of the search we can start scraping using the URL we just acquired. For the sake of simplicity, we use the Gazpacho library.\n",
    "\n",
    "In the following cell we collect the URLs for each listing by go through the results page by page.\n",
    "\n",
    "We use the tqdm library to see the progress more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2263e297921e4b32aa8969726393315a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gazpacho import get, Soup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "new_houses = []\n",
    "\n",
    "html = get(url)\n",
    "soup = Soup(html)\n",
    "\n",
    "n_pages = int(soup.find('div',{'class':'pagination'}).find('div',{'class':'info'}).text.split(\" \")[-1])\n",
    "for i in tqdm(range(n_pages)):\n",
    "    if i != 0:\n",
    "        next_page = soup.find('span',{'class':'next'}).find('a').attrs['href']\n",
    "        url = \"https://www.mbl.is\" + next_page\n",
    "        html = get(url)\n",
    "        soup = Soup(html)\n",
    "    \n",
    "    houses = soup.find('div', {'id': 'realestate-result-'}, partial=True)\n",
    "    for house in houses:\n",
    "        url = house.find('div',{'class':'realestate-head'}).find('a').attrs['href']\n",
    "        house_id = url.split(\"/\")[-2]\n",
    "        house_name = house.find('div',{'class':'realestate-head'}).find('h4').text\n",
    "\n",
    "        d = {\"url\":url,\"house_id\":house_id,\"house_name\":house_name}\n",
    "\n",
    "        new_houses.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting the links for all the new listings we scrape each page separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09b03356fa844359294d38e66dfb713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=228), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for house in tqdm(new_houses):\n",
    "    url = \"https://www.mbl.is\" + house[\"url\"]\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    info_table = soup.find('div',{'class':'numbers'}).find('tr')\n",
    "\n",
    "    try:\n",
    "        house['fasteignasala'] = info_table[0].find('img').attrs['alt']\n",
    "    except:\n",
    "        house['fasteignasala'] = None\n",
    "\n",
    "    for row in info_table[1:-1]:\n",
    "        label_text = row.text\n",
    "        value = row.find('td',{'class':'value'}).text\n",
    "        house[label_text] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make sure that you can turn your data into a usable dataset. It is is easy to create a CSV file, for example, with Pandas as I show in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_houses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-23ff19bef71f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_houses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new_listings.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_houses' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(new_houses)\n",
    "df.to_csv(\"new_listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more things that can be done with this approach. For example, get the images from each listing, clean the data such that the price is an integer.\n",
    "\n",
    "You could an analysis of the description text for each listing, what words are indicative of extra features that might be interesting to use in your prediction modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
