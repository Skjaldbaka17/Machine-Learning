{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#import all modules\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Activation\n",
    "from tensorflow.keras.layers import Conv2D,BatchNormalization,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirname = []\n",
    "Filenames =[]\n",
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        Dirname.append(dirname)\n",
    "        Filenames.append(filename)\n",
    "        X = os.path.join(dirname, filename)\n",
    "print(Filenames)        \n",
    "        #print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir = '/kaggle/input/face-mask-detection'\n",
    "print(os.listdir(Dir))\n",
    "images_path = os.path.join(Dir,'images')\n",
    "print(\"Image path = {}\".format(images_path))\n",
    "print(\"Total number of images : {}\".format(len(os.listdir(images_path))))\n",
    "Annotation_path = '/kaggle/input/face-mask-detection/annotations'\n",
    "print(\"Annotation path = {}\".format(Annotation_path))\n",
    "print(\"Total Annotation files are {}\".format(len(os.listdir(Annotation_path))))\n",
    "\n",
    "Image_width = 80\n",
    "Image_height = 80\n",
    "Image_array = []\n",
    "Labels = []\n",
    "\n",
    "#Check label files are according to images files\n",
    "Sorted_files = sorted(os.listdir(Annotation_path))\n",
    "print(Sorted_files)\n",
    "Sorted_images_path = sorted(os.listdir(images_path))\n",
    "print(Sorted_images_path)\n",
    "\n",
    "# Prepare data and respective labels\n",
    "def get_box(obj):\n",
    "    \n",
    "    xmin = int(obj.find('xmin').text)\n",
    "    ymin = int(obj.find('ymin').text)\n",
    "    xmax = int(obj.find('xmax').text)\n",
    "    ymax = int(obj.find('ymax').text)\n",
    "    \n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "\n",
    "for file in tqdm(sorted(os.listdir(Annotation_path)),desc='Preparing data..'):\n",
    "    file_path = Annotation_path + \"/\" + file\n",
    "    xml = ET.parse(file_path)\n",
    "    root = xml.getroot()\n",
    "    image_path = images_path + \"/\" + root[1].text\n",
    "\n",
    "     \n",
    "    for bndbox in root.iter('bndbox'):\n",
    "        [xmin, ymin, xmax, ymax] = get_box(bndbox)\n",
    "        img = cv2.imread(image_path)\n",
    "        face_img = img[ymin:ymax,xmin:xmax]\n",
    "        face_img  = cv2.resize(face_img,(Image_width,Image_height))\n",
    "        Image_array.append(np.array(face_img)) \n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text \n",
    "        Labels.append(np.array(name)) \n",
    "        \n",
    "#Normalize the data\n",
    "num_classes = 3\n",
    "X = np.array(Image_array)\n",
    "X = X/255\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(Labels)\n",
    "y  = to_categorical(y,num_classes)\n",
    "\n",
    "#Check the total Images and label length are equal \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "#Check random images \n",
    "fig,ax = plt.subplots(2,2)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        l = rn.randint(0,len(Labels))\n",
    "        ax[i,j].imshow(Image_array[l])\n",
    "        ax[i,j].set_title(Labels[l])\n",
    "        \n",
    "#Split the data for training and validation        \n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.20,random_state = 42)\n",
    "#Check the total training images\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)  \n",
    "\n",
    "# design model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64,kernel_size = (3,3),activation = 'relu',padding = 'same',input_shape = (Image_width,Image_height,3)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96,kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 128,kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
    "model.add(Conv2D(filters = 128,kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dense(3,activation = \"softmax\"))\n",
    "\n",
    "\n",
    "Batch_size = 64\n",
    "Epochs = 20\n",
    "seed = 1000\n",
    "\n",
    "#Augmented Images\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rotation_range = 10,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range = 0.2,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True,\n",
    "                    fill_mode = 'nearest')\n",
    "#Callbacks\n",
    "Estop = EarlyStopping(monitor = 'val_loss',patience = 2,verbose = 1,min_delta = 0.01)\n",
    "#Red_lr = ReduceLROnPlateau(monitor = 'val_accuracy',patience = 3,verbose = 1,factor = 0.1)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer = Adam(lr = 0.001),loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit_generator(train_datagen.flow(X_train,y_train,batch_size = Batch_size),steps_per_epoch = X_train.shape[0]//Batch_size,epochs = Epochs,validation_data = (X_val,y_val),verbose=1,callbacks=[Estop])\n",
    "\n",
    "#plot the history\n",
    "def plot_model_performance(history):\n",
    "    fig =plt.figure(figsize = (20,20))\n",
    "    #plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','test'],loc =\"upper left\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plot loss \n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model_loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','test'],loc =\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "plot_model_performance(history)\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
